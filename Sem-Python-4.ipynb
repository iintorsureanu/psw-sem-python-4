{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Python 4: Pachetul scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplu instalare pachet scikit-learn: în (Windows) Command prompt / (UNIX) fereastră Terminal / shell se rulează:\n",
    "`pip install scikit-learn`\n",
    "\n",
    "Similar și pentru alte pachete Python: scipy, six, cycler, pyparsing, kiwisolver, python-dateutil, matplotlib, pytz, pandas, seaborn, numpy, sklearn, statsmodels etc.  \n",
    "După caz, poate fi necesar upgrade-ul PIP (Python package installer) - v. mai multe detalii pe https://datatofish.com/upgrade-pip/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificare pachet/modul instalat (tratare excepție în caz de eșec import cu try...except)\n",
    "try:                 \n",
    "    import sklearn\n",
    "    print('Import OK.')\n",
    "except ImportError as err: \n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalare in Jupyter Lab: #\"comandă magică\" IPython, rulează în shell\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterizare K-Means în Python cu pachetul scikit-learn\n",
    "Metoda de clusterizare K-means realizează gruparea observațiilor dintr-un set de date într-un număr de K \"clustere\" - grupuri de observații care prezintă similarități."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 1. Gruparea unui set de valori în 3 clustere\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.array([[5,3],\n",
    "     [10,15],\n",
    "     [15,12],\n",
    "     [24,10],\n",
    "     [30,45],\n",
    "     [85,70],\n",
    "     [71,80],\n",
    "     [60,78],\n",
    "     [55,52],\n",
    "     [80,91]])\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "print(kmeans.cluster_centers_)\n",
    "print(kmeans.labels_)\n",
    "f1 = plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], label='True Position')\n",
    "f2 = plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=kmeans.labels_, cmap='rainbow')\n",
    "f3 = plt.figure()\n",
    "plt.scatter(kmeans.cluster_centers_[:,0] ,kmeans.cluster_centers_[:,1], color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Această metodă este utilizată în învățarea automată (_machine learning_) pentru a identifica clusterele pe baza unui set de antrenare (train); pe această bază se vor face predicții privind apartenența altor observații (din setul de test) la clusterele identificate (v. mai multe detalii [aici](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1))\n",
    "\n",
    "**Aplicație**  \n",
    "Scufundarea Titanicului în 1912 a dus la 1502 victime din cei 2224 pasageri și membri ai echipajului.\n",
    "Se vor utiliza două seturi de date `train.csv` și `test.csv`, ce conțin informații legate de pasageri. Diferența majoră dintre cele două seturi la nivel de coloane constă în coloana `Survived`,  prezentă doar în setul de antrenare. Se poate considera că supraviețuirea a fost influențată de anumite atribute, cum ar fi vârsta, sexul, clasa biletului de călătorie etc. Pornind de la aceste caracteristici, se vor grupa (clusteriza) pasagerii din setul de date de antrenare în două clustere (supraviețuitori / nesupraviețuitori); pe baza acestora se vor face predicții privind apartenența pasagerilor din setul de test la unul dintre clustere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 1. Import biblioteci\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 2. Citirea fișierelor și afișarea primelor 5 înregistrări\n",
    "pd.options.display.max_columns = 12\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "print('*****test*****')\n",
    "print(test.head())\n",
    "print('*****train*****')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 3. Calcul statistici de bază\n",
    "print('*****test_stats*****')\n",
    "print(test.describe())\n",
    "print('*****train_stats*****')\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anumiți algoritmi machine learning, inclusiv k-means, nu permit valori lipsă. Astfel, vor fi identificate valorile lipsă."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 4. Vizualizare denumire coloane din setul train și indentificare valori lipsă\n",
    "print(train.columns.values)\n",
    "\n",
    "print('*****train_ valori_lipsă *****')\n",
    "print(train.isna())\n",
    "print('*****test_valori_lipsă*****')\n",
    "print(test.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 5. Calcul număr valori lipsă pentru coloanele celor două seturi de date\n",
    "print(\"*****In the train set*****\")\n",
    "print(train.isna().sum())\n",
    "print(\"\\n\")\n",
    "print('*****In the test set*****')\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 6. Înlocuirea valorilor lipsă cu media coloanei, utilizând fillna()\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "print(train.isna().sum())\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 7. Evaluarea supraviețuitorilor în funcție de Pclass, Sex, SibSp\n",
    "print(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
    "print(train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 8. Reprezentare grafică a coloanelor Age-Survived și Pclass-Survived\n",
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g.map(plt.hist, 'Age')\n",
    "grid = sns.FacetGrid(train, col='Survived', row='Pclass')\n",
    "grid.map(plt.hist, 'Age')\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 9. Afișarea informațiilor legate de setul de date train\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 10. Eliminarea coloanelor non-numerice care nu influențează supraviețuirea\n",
    "train = train.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)\n",
    "test = test.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 11. Transformarea tipului de dată a coloanei Sex\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(train['Sex'])\n",
    "labelEncoder.fit(test['Sex'])\n",
    "train['Sex'] = labelEncoder.transform(train['Sex'])\n",
    "test['Sex'] = labelEncoder.transform(test['Sex'])\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 12. Var. X este un vector (array din pachetul numpy) identic cu setul train,\n",
    "# din care a fost ștearsă coloana Survived, iar y este un vector format din coloana Survived\n",
    "X = np.array(train.drop(['Survived'], 1).astype(float))\n",
    "y = np.array(train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 13. Aplearea metodei Kmeans și setarea parametrului n_clusters = 2\n",
    "# (supraviețuitori/nesupraviețuitori). \n",
    "kmeans = KMeans(n_clusters=2) \n",
    "#kmeans = KMeans(n_clusters=2, max_iter=600)\n",
    "kmeans.fit(X)\n",
    "\n",
    "#Alte setări (argumente) posibile pentru kmeans:\n",
    "'''KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
    "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
    "    random_state=None, tol=0.0001, verbose=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 2. Pas 14. Evaluarea rezultatelor\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelul clusterizează correct cu o acuratețe de circa 50%.  \n",
    "Pentru o îmbunățire a rezultatelor, se vor scala datele de intrare.  \n",
    "Exemplul 2, pas 15: deschideți și rulați `Ex_2_15.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NU EXECUTAȚI ACEASTĂ CELULĂ --- #\n",
    "#Exemplu 2. Cod complet exemplu KMmeans - salvat și ca script (fișier) ex_2.py,\n",
    "#pentru rulare separată (în fereastră Terminal / IDLE / PyCharm)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 12\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "print('*****test*****')\n",
    "print(test.head())\n",
    "print('*****train*****')\n",
    "print(train.head())\n",
    "\n",
    "print('*****test_stats*****')\n",
    "print(test.describe())\n",
    "print('*****train_stats*****')\n",
    "print(train.describe())\n",
    "\n",
    "print(train.columns.values)\n",
    "\n",
    "print(train.isna())\n",
    "print(test.isna())\n",
    "\n",
    "print('*****In the train set*****')\n",
    "print(train.isna().sum())\n",
    "print(\"\\n\")\n",
    "print('*****In the test set*****')\n",
    "print(test.isna().sum())\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "print(train.isna().sum())\n",
    "print(test.isna().sum())\n",
    "\n",
    "\n",
    "print(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
    "print(train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
    "print(train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
    "\n",
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g.map(plt.hist, 'Age')\n",
    "grid = sns.FacetGrid(train, col='Survived', row='Pclass')\n",
    "grid.map(plt.hist, 'Age')\n",
    "grid.add_legend()\n",
    "plt.show()\n",
    "\n",
    "train.info()\n",
    "\n",
    "train = train.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)\n",
    "test = test.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(train['Sex'])\n",
    "labelEncoder.fit(test['Sex'])\n",
    "train['Sex'] = labelEncoder.transform(train['Sex'])\n",
    "test['Sex'] = labelEncoder.transform(test['Sex'])\n",
    "\n",
    "train.info()\n",
    "\n",
    "test.info()\n",
    "\n",
    "X = np.array(train.drop(['Survived'], 1).astype(float))\n",
    "\n",
    "y = np.array(train['Survived'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_scaled)\n",
    "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=600,\n",
    "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
    "    random_state=None, tol=0.0001, verbose=0)\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresie logistică\n",
    "Această metodă de machine learning este utilizată pentru probleme de clasificare - predicția apartenenței sau nu a unei observații la o clasă (regresie logistică binară) - de ex. pasager supraviețuitor sau nu.  \n",
    "Se urmărește determinarea unei ecuații de regresie bazată pe funcția sigmoidă (funcția logistică), în loc de o dreaptă ca la regresia liniară (v. mai multe detalii [aici](https://towardsdatascience.com/introduction-to-logistic-regression-66248243c148)).  \n",
    "Ecuația de regresie este estimată pe baza datelor din setul de antrenare (train). Apoi se vor face predicții asupra setului de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 3. Regresie logistică (logistic regression)\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pd.options.display.max_columns = 12\n",
    "test = pd.read_csv('test1.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "print('*****test*****')\n",
    "print(test[:4])\n",
    "print('*****train*****')\n",
    "print(train[:4])\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "print(train.isna().sum())\n",
    "print(test.isna().sum())\n",
    "\n",
    "train['IsFemale'] = (train['Sex'] == 'female').astype(int)\n",
    "test['IsFemale'] = (test['Sex'] == 'female').astype(int)\n",
    "\n",
    "predictors = ['Pclass', 'IsFemale', 'Age']\n",
    "X_train = train[predictors].values\n",
    "X_test = test[predictors].values\n",
    "y_train = train['Survived'].values\n",
    "y_test= test['Survived'].values\n",
    "print(X_train[:5])\n",
    "print(y_train[:5])\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
    "verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(y_predict)\n",
    "\n",
    "print((y_test == y_predict).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresie liniară simplă"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 4. Regresie simplă liniară (Ordinary Least Squares)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "pd.options.display.max_columns = 12\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "train['IsFemale'] = (train['Sex'] == 'female').astype(int)\n",
    "test['IsFemale'] = (test['Sex'] == 'female').astype(int)\n",
    "\n",
    "X_train = train['IsFemale'].values\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "results = model.fit()\n",
    "print(results.params)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresie liniară multiplă"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplu 5. Regresie multiplă (multiple regression)\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "pd.options.display.max_columns = 12\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "train['IsFemale'] = (train['Sex'] == 'female').astype(int)\n",
    "test['IsFemale'] = (test['Sex'] == 'female').astype(int)\n",
    "\n",
    "\n",
    "X = pd.DataFrame(train, columns=['Pclass', 'IsFemale', 'Age'])\n",
    "y = train['Survived']\n",
    "\n",
    "results = smf.ols('y ~ Pclass + IsFemale + Age', data=train).fit()\n",
    "print(results.params)\n",
    "\n",
    "print(round(results.predict(train[:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referințe\n",
    "1. J. VanderPlas, Python Data Science Handbook: https://jakevdp.github.io/PythonDataScienceHandbook/index.html, Cap. 5\n",
    "1. https://stackabuse.com/k-means-clustering-with-scikit-learn/ \n",
    "2. https://www.datacamp.com/community/tutorials/k-means-clustering-python\n",
    "3. Wes McKinney, 2nd Edition of Python for Data Analysis DATA WRANGLING WITH PANDAS, NUMPY, AND IPYTHON, O’Reilley\n",
    "4. https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc \n",
    "5. https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
